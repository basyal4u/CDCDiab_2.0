{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Classifer Model\n",
    "\n",
    "## It consist of Logistic regression, K-NN, Decison Tree, Support Vector Machine and Artifical Neural Network(ANN). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob \n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Ganga\\\\Desktop\\\\Research\\\\CDCDiab1\\\\07-08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Ganga\\\\Desktop\\\\Research\\\\CDCDiab1\\\\07-08'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the DataSet\n",
    "CDCDataset = pd.read_csv('07_08Final.csv')\n",
    "CLANN = CDCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10149, 3753)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLANN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0        0\n",
      "SEQN              0\n",
      "AUXRR101       9010\n",
      "AUXRR102       9010\n",
      "AUXRR103       9010\n",
      "AUXRR104       9010\n",
      "AUXRR105       9010\n",
      "AUXRR106       9010\n",
      "AUXRR107       9010\n",
      "AUXRR108       9010\n",
      "AUXRR109       9010\n",
      "AUXRR110       9010\n",
      "AUXRR111       9010\n",
      "AUXRR112       9010\n",
      "AUXRR113       9010\n",
      "AUXRR114       9010\n",
      "AUXRR115       9010\n",
      "AUXRR116       9010\n",
      "AUXRR117       9010\n",
      "AUXRR118       9010\n",
      "AUXRR119       9010\n",
      "AUXRR120       9010\n",
      "AUXRR121       9010\n",
      "AUXRR122       9010\n",
      "AUXRR123       9010\n",
      "AUXRR124       9010\n",
      "AUXRR125       9010\n",
      "AUXRR126       9010\n",
      "AUXRR127       9010\n",
      "AUXRR128       9010\n",
      "              ...  \n",
      "WHQ270         7566\n",
      "WHQ280A       10068\n",
      "WHQ280B       10109\n",
      "WHQ280C       10099\n",
      "WHQ280D       10064\n",
      "WHQ280E       10128\n",
      "WHQ090         6228\n",
      "WHD100A        9910\n",
      "WHD100B       10010\n",
      "WHD100C        9953\n",
      "WHD100D        9892\n",
      "WHD100E       10093\n",
      "WHD100F       10130\n",
      "WHD100G       10141\n",
      "WHD100J       10143\n",
      "WHD100L       10145\n",
      "WHD100M       10023\n",
      "WHD100N       10143\n",
      "WHD100O       10054\n",
      "WHD100P       10144\n",
      "WHD100Q       10146\n",
      "WHD100R       10141\n",
      "WHD100S       10146\n",
      "WHQ210         6228\n",
      "WHD220         6509\n",
      "WHD110         5775\n",
      "WHD120         4968\n",
      "WHD130         7123\n",
      "WHD140         3986\n",
      "WHQ150         4077\n",
      "Length: 3753, dtype: int64\n",
      "(10149, 166)\n"
     ]
    }
   ],
   "source": [
    "# if more than 20% of the values are missing then we drop, because data are to sparse\n",
    "s = CLANN.isnull().apply(sum, axis=0) # count the number of nan in each column\n",
    "print(s) \n",
    "\n",
    "for col in CLANN: \n",
    "    if s[col] >= 0.10*10149:  \n",
    "        del CLANN[col]\n",
    "   \n",
    "print(CLANN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10149, 166)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLANN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0   SEQN  BMDSTATS  BMXWT  BMXARML  BMXARMC  PEASCST1  \\\n",
      "0               0  41475       3.0  138.9     37.6     45.2       1.0   \n",
      "1               1  41476       1.0   22.0     25.1     17.1       1.0   \n",
      "2               2  41477       1.0   83.9     38.2     34.1       1.0   \n",
      "3               3  41478       1.0   11.5     14.2     17.3       1.0   \n",
      "4               4  41479       1.0   65.7     34.1     33.2       1.0   \n",
      "5               5  41480       1.0   27.0     25.8     20.9       1.0   \n",
      "6               6  41481       1.0   77.9     43.0     31.0       1.0   \n",
      "7               7  41482       1.0  101.6     40.0     32.8       1.0   \n",
      "8               8  41483       3.0  133.1     38.9     40.5       1.0   \n",
      "9               9  41484       1.0    9.3     14.5     15.2       1.0   \n",
      "10             10  41485       1.0   64.8     32.6     30.7       1.0   \n",
      "11             11  41486       1.0   86.2     36.0     35.3       1.0   \n",
      "12             12  41487       1.0   67.1     37.0     29.9       1.0   \n",
      "13             13  41488       1.0   16.1     22.0     17.0       1.0   \n",
      "14             14  41489       1.0   91.8     34.0     37.8       1.0   \n",
      "15             15  41490       1.0   70.7     37.0     31.2       1.0   \n",
      "16             16  41491       1.0   33.5     29.5     20.8       1.0   \n",
      "17             17  41492       1.0   82.6     39.0     34.0       1.0   \n",
      "18             18  41493       1.0   53.3     36.6     21.9       1.0   \n",
      "19             19  41494       1.0   70.5     36.4     32.0       1.0   \n",
      "20             20  41495       1.0   87.2     41.7     32.6       1.0   \n",
      "21             21  41496       1.0   67.8     35.2     33.3       1.0   \n",
      "22             22  41497       3.0   12.5     17.6     13.8       1.0   \n",
      "23             23  41498       3.0   77.4     39.0     31.1       1.0   \n",
      "24             24  41499       4.0    NaN      NaN      NaN       1.0   \n",
      "25             25  41500       1.0   91.6     33.0     35.4       1.0   \n",
      "26             26  41501       3.0  114.8     39.2     37.2       1.0   \n",
      "27             27  41502       1.0   82.4     38.5     36.6       1.0   \n",
      "28             28  41503       1.0   73.1     36.9     30.6       1.0   \n",
      "29             29  41504       1.0   74.3     40.0     29.0       1.0   \n",
      "...           ...    ...       ...    ...      ...      ...       ...   \n",
      "10119       10119  51594       1.0   87.3     39.0     38.6       1.0   \n",
      "10120       10120  51595       NaN    NaN      NaN      NaN       NaN   \n",
      "10121       10121  51596       3.0   75.8     33.3     37.8       1.0   \n",
      "10122       10122  51597       1.0   28.8     26.8     21.6       1.0   \n",
      "10123       10123  51598       1.0    6.5     12.6     14.2       1.0   \n",
      "10124       10124  51599       1.0    8.9     16.2     14.0       1.0   \n",
      "10125       10125  51600       1.0   15.3     18.0     17.2       1.0   \n",
      "10126       10126  51601       1.0   28.4     26.6     22.4       1.0   \n",
      "10127       10127  51602       NaN    NaN      NaN      NaN       NaN   \n",
      "10128       10128  51603       1.0   63.7     39.0     26.9       3.0   \n",
      "10129       10129  51604       1.0   91.3     39.4     41.2       1.0   \n",
      "10130       10130  51605       1.0    9.1     15.0     14.5       1.0   \n",
      "10131       10131  51606       1.0   49.0     35.3     22.8       1.0   \n",
      "10132       10132  51607       1.0   17.5     21.2     16.0       1.0   \n",
      "10133       10133  51608       1.0   75.9     35.4     30.7       1.0   \n",
      "10134       10134  51609       1.0   79.9     38.3     32.3       1.0   \n",
      "10135       10135  51610       1.0   86.8     34.0     37.3       1.0   \n",
      "10136       10136  51611       1.0   68.4     36.3     30.3       1.0   \n",
      "10137       10137  51612       1.0   23.3     24.5     17.7       1.0   \n",
      "10138       10138  51613       1.0   81.6     37.2     35.7       1.0   \n",
      "10139       10139  51614       1.0   71.7     38.6     31.3       1.0   \n",
      "10140       10140  51615       2.0   50.4      NaN      NaN       3.0   \n",
      "10141       10141  51616       3.0  142.6     44.0     44.0       1.0   \n",
      "10142       10142  51617       1.0   77.9     36.3     34.5       1.0   \n",
      "10143       10143  51618       1.0   90.6     39.5     36.6       1.0   \n",
      "10144       10144  51619       1.0   89.4     39.5     33.9       1.0   \n",
      "10145       10145  51620       1.0   72.2     35.7     29.3       1.0   \n",
      "10146       10146  51621       1.0   42.8     33.2     22.2       1.0   \n",
      "10147       10147  51622       1.0   79.1     38.0     37.5       1.0   \n",
      "10148       10148  51623       1.0   85.2     38.3     33.3       1.0   \n",
      "\n",
      "       PEASCTM1  BPXPULS     WTDRD1_x_x   ...    MCQ053  MCQ140  PAAQUEX  \\\n",
      "0         612.0      1.0   53942.247630   ...       2.0     1.0      1.0   \n",
      "1           9.0      1.0   20558.408370   ...       2.0     2.0      1.0   \n",
      "2         625.0      1.0    9050.134179   ...       2.0     2.0      1.0   \n",
      "3         278.0      1.0   32343.214640   ...       2.0     NaN      NaN   \n",
      "4         620.0      1.0    5078.443529   ...       2.0     2.0      1.0   \n",
      "5          79.0      1.0    3723.882672   ...       2.0     2.0      1.0   \n",
      "6         533.0      1.0   12870.996030   ...       2.0     2.0      1.0   \n",
      "7         561.0      1.0    7517.688697   ...       2.0     1.0      1.0   \n",
      "8         748.0      1.0    7180.607302   ...       2.0     1.0      1.0   \n",
      "9         285.0      1.0    6641.977082   ...       NaN     NaN      NaN   \n",
      "10        547.0      1.0   38644.908770   ...       2.0     2.0      1.0   \n",
      "11        556.0      1.0    3522.439021   ...       2.0     2.0      1.0   \n",
      "12        539.0      1.0   52595.083820   ...       2.0     2.0      1.0   \n",
      "13         59.0      1.0   18956.928130   ...       2.0     2.0      1.0   \n",
      "14        570.0      1.0   14249.810570   ...       2.0     2.0      1.0   \n",
      "15        564.0      1.0    9558.697213   ...       2.0     2.0      1.0   \n",
      "16        555.0      1.0   13326.978710   ...       2.0     2.0      1.0   \n",
      "17        704.0      1.0    8361.116109   ...       2.0     2.0      1.0   \n",
      "18        567.0      1.0   78473.745560   ...       2.0     2.0      1.0   \n",
      "19        670.0      1.0    8305.458257   ...       2.0     2.0      1.0   \n",
      "20        676.0      1.0   96206.169540   ...       2.0     1.0      1.0   \n",
      "21        676.0      1.0    8077.125819   ...       2.0     1.0      1.0   \n",
      "22         20.0      1.0   19581.040440   ...       2.0     2.0      1.0   \n",
      "23        698.0      1.0    7551.420843   ...       2.0     2.0      1.0   \n",
      "24        467.0      1.0    8855.089300   ...       2.0     2.0      1.0   \n",
      "25        531.0      1.0    7922.947978   ...       2.0     1.0      2.0   \n",
      "26        574.0      1.0   27913.044170   ...       2.0     2.0      1.0   \n",
      "27        516.0      1.0   15175.424640   ...       2.0     2.0      1.0   \n",
      "28        625.0      1.0   42482.659470   ...       2.0     2.0      1.0   \n",
      "29        743.0      1.0   51977.247980   ...       2.0     2.0      1.0   \n",
      "...         ...      ...            ...   ...       ...     ...      ...   \n",
      "10119     548.0      1.0   17328.980470   ...       2.0     1.0      1.0   \n",
      "10120       NaN      NaN            NaN   ...       2.0     2.0      1.0   \n",
      "10121     662.0      1.0   10619.946750   ...       2.0     2.0      1.0   \n",
      "10122     286.0      1.0    5104.801100   ...       2.0     2.0      1.0   \n",
      "10123      28.0      1.0    4005.651240   ...       NaN     NaN      NaN   \n",
      "10124     284.0      1.0    7595.604510   ...       2.0     NaN      NaN   \n",
      "10125     300.0      1.0    7625.832026   ...       2.0     2.0      1.0   \n",
      "10126     274.0      1.0   14336.700480   ...       2.0     2.0      1.0   \n",
      "10127       NaN      NaN            NaN   ...       2.0     2.0      1.0   \n",
      "10128       NaN      NaN   33245.288840   ...       2.0     2.0      1.0   \n",
      "10129     647.0      1.0  178652.451300   ...       2.0     2.0      1.0   \n",
      "10130     285.0      1.0   10325.821360   ...       NaN     NaN      NaN   \n",
      "10131     519.0      1.0   23924.308540   ...       2.0     2.0      1.0   \n",
      "10132      63.0      1.0   90063.114920   ...       2.0     2.0      1.0   \n",
      "10133     635.0      1.0   17803.033790   ...       2.0     2.0      1.0   \n",
      "10134     471.0      1.0   41060.243290   ...       2.0     2.0      1.0   \n",
      "10135     595.0      1.0    3114.070668   ...       2.0     1.0      1.0   \n",
      "10136     688.0      1.0   53791.255800   ...       2.0     2.0      1.0   \n",
      "10137     330.0      1.0   18823.450820   ...       2.0     1.0      1.0   \n",
      "10138     487.0      1.0   18359.625980   ...       2.0     2.0      2.0   \n",
      "10139     524.0      1.0   15364.874330   ...       2.0     1.0      1.0   \n",
      "10140       NaN      NaN            NaN   ...       2.0     2.0      1.0   \n",
      "10141     882.0      2.0   96424.894890   ...       2.0     1.0      1.0   \n",
      "10142     666.0      1.0    9670.280715   ...       2.0     2.0      1.0   \n",
      "10143     533.0      1.0   56879.743240   ...       2.0     2.0      1.0   \n",
      "10144     552.0      1.0    3492.609773   ...       2.0     2.0      1.0   \n",
      "10145     445.0      1.0   49188.089970   ...       1.0     1.0      1.0   \n",
      "10146     563.0      1.0    5593.553537   ...       2.0     2.0      1.0   \n",
      "10147     612.0      1.0   17844.521900   ...       2.0     1.0      1.0   \n",
      "10148     754.0      1.0   24704.093160   ...       2.0     2.0      1.0   \n",
      "\n",
      "       RDQ070  RDQ140  AGQ030  RXDUSE  \\\n",
      "0         1.0     1.0     9.0       1   \n",
      "1         2.0     2.0     2.0       1   \n",
      "2         2.0     2.0     2.0       1   \n",
      "3         2.0     2.0     2.0       2   \n",
      "4         2.0     2.0     2.0       2   \n",
      "5         2.0     2.0     2.0       2   \n",
      "6         2.0     2.0     2.0       2   \n",
      "7         2.0     2.0     2.0       1   \n",
      "8         2.0     2.0     1.0       1   \n",
      "9         NaN     NaN     NaN       2   \n",
      "10        2.0     2.0     2.0       2   \n",
      "11        2.0     2.0     2.0       1   \n",
      "12        2.0     2.0     2.0       2   \n",
      "13        2.0     2.0     2.0       2   \n",
      "14        2.0     2.0     2.0       2   \n",
      "15        2.0     2.0     2.0       1   \n",
      "16        2.0     2.0     2.0       2   \n",
      "17        2.0     2.0     2.0       2   \n",
      "18        2.0     1.0     1.0       1   \n",
      "19        2.0     2.0     2.0       2   \n",
      "20        2.0     1.0     1.0       1   \n",
      "21        2.0     1.0     2.0       2   \n",
      "22        2.0     2.0     2.0       2   \n",
      "23        1.0     2.0     2.0       1   \n",
      "24        2.0     2.0     2.0       2   \n",
      "25        2.0     2.0     2.0       2   \n",
      "26        2.0     2.0     2.0       1   \n",
      "27        1.0     2.0     2.0       1   \n",
      "28        2.0     2.0     2.0       2   \n",
      "29        2.0     2.0     2.0       1   \n",
      "...       ...     ...     ...     ...   \n",
      "10119     2.0     2.0     2.0       2   \n",
      "10120     2.0     2.0     1.0       2   \n",
      "10121     2.0     2.0     2.0       2   \n",
      "10122     2.0     2.0     2.0       2   \n",
      "10123     NaN     NaN     NaN       2   \n",
      "10124     2.0     2.0     2.0       2   \n",
      "10125     1.0     2.0     2.0       2   \n",
      "10126     2.0     2.0     2.0       2   \n",
      "10127     2.0     2.0     2.0       2   \n",
      "10128     2.0     2.0     1.0       1   \n",
      "10129     1.0     2.0     1.0       1   \n",
      "10130     NaN     NaN     NaN       1   \n",
      "10131     2.0     2.0     2.0       1   \n",
      "10132     2.0     2.0     1.0       2   \n",
      "10133     2.0     2.0     2.0       2   \n",
      "10134     1.0     2.0     2.0       1   \n",
      "10135     2.0     2.0     2.0       1   \n",
      "10136     2.0     2.0     2.0       2   \n",
      "10137     1.0     2.0     2.0       2   \n",
      "10138     1.0     2.0     1.0       1   \n",
      "10139     1.0     2.0     2.0       1   \n",
      "10140     2.0     2.0     2.0       1   \n",
      "10141     2.0     2.0     2.0       1   \n",
      "10142     2.0     2.0     2.0       1   \n",
      "10143     2.0     2.0     1.0       2   \n",
      "10144     2.0     1.0     1.0       1   \n",
      "10145     1.0     2.0     2.0       2   \n",
      "10146     2.0     2.0     2.0       2   \n",
      "10147     2.0     2.0     2.0       2   \n",
      "10148     2.0     2.0     2.0       1   \n",
      "\n",
      "                                                 RXDDRUG   RXDDRGID  SMD410  \n",
      "0                                            b'ATENOLOL'  b'd00004'     2.0  \n",
      "1                                   b'MUPIROCIN TOPICAL'  b'd01267'     2.0  \n",
      "2                                           b'GLIPIZIDE'  b'd00246'     2.0  \n",
      "3                                                    b''        b''     1.0  \n",
      "4                                                    b''        b''     2.0  \n",
      "5                                                    b''        b''     2.0  \n",
      "6                                                    b''        b''     2.0  \n",
      "7                                          b'AMLODIPINE'  b'd00689'     2.0  \n",
      "8                                           b'DOXAZOSIN'  b'd00726'     2.0  \n",
      "9                                                    b''        b''     2.0  \n",
      "10                                                   b''        b''     2.0  \n",
      "11                                b'HYDROCHLOROTHIAZIDE'  b'd00253'     2.0  \n",
      "12                                                   b''        b''     2.0  \n",
      "13                                                   b''        b''     2.0  \n",
      "14                                                   b''        b''     2.0  \n",
      "15                                         b'RALOXIFENE'  b'd04261'     2.0  \n",
      "16                                                   b''        b''     2.0  \n",
      "17                                                   b''        b''     2.0  \n",
      "18                             b'ALBUTEROL; IPRATROPIUM'  b'd04066'     1.0  \n",
      "19                                                   b''        b''     2.0  \n",
      "20                                         b'ALPRAZOLAM'  b'd00168'     2.0  \n",
      "21                                                   b''        b''     2.0  \n",
      "22                                                   b''        b''     2.0  \n",
      "23                                          b'ALBUTEROL'  b'd00749'     2.0  \n",
      "24                                                   b''        b''     2.0  \n",
      "25                                                   b''        b''     2.0  \n",
      "26                                           b'ATENOLOL'  b'd00004'     2.0  \n",
      "27                                         b'PENICILLIN'  b'd00116'     2.0  \n",
      "28                                                   b''        b''     NaN  \n",
      "29                                       b'ATORVASTATIN'  b'd04105'     2.0  \n",
      "...                                                  ...        ...     ...  \n",
      "10119                                                b''        b''     2.0  \n",
      "10120                                                b''        b''     2.0  \n",
      "10121                                                b''        b''     2.0  \n",
      "10122                                                b''        b''     2.0  \n",
      "10123                                                b''        b''     2.0  \n",
      "10124                                                b''        b''     2.0  \n",
      "10125                                                b''        b''     2.0  \n",
      "10126                                                b''        b''     1.0  \n",
      "10127                                                b''        b''     2.0  \n",
      "10128                                           b'99999'        b''     2.0  \n",
      "10129                                    b'FEXOFENADINE'  b'd04040'     2.0  \n",
      "10130  b'BROMPHENIRAMINE; DEXTROMETHORPHAN; PSEUDOEPH...  b'd03368'     2.0  \n",
      "10131                          b'EZETIMIBE; SIMVASTATIN'  b'd05348'     2.0  \n",
      "10132                                                b''        b''     2.0  \n",
      "10133                                                b''        b''     1.0  \n",
      "10134                                     b'SUMATRIPTAN'  b'd03160'     2.0  \n",
      "10135                                       b'GLYBURIDE'  b'd00248'     2.0  \n",
      "10136                                                b''        b''     2.0  \n",
      "10137                                                b''        b''     2.0  \n",
      "10138                          b'ALBUTEROL; IPRATROPIUM'  b'd04066'     2.0  \n",
      "10139                      b'ACETAMINOPHEN; HYDROCODONE'  b'd03428'     1.0  \n",
      "10140                                      b'LISINOPRIL'  b'd00732'     2.0  \n",
      "10141                                       b'DOXAZOSIN'  b'd00726'     2.0  \n",
      "10142                                      b'FELODIPINE'  b'd00231'     2.0  \n",
      "10143                                                b''        b''     2.0  \n",
      "10144                                      b'BENAZEPRIL'  b'd00730'     2.0  \n",
      "10145                                                b''        b''     2.0  \n",
      "10146                                                b''        b''     2.0  \n",
      "10147                                                b''        b''     2.0  \n",
      "10148                                       b'ENALAPRIL'  b'd00013'     2.0  \n",
      "\n",
      "[10149 rows x 166 columns]\n"
     ]
    }
   ],
   "source": [
    "print(CLANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLANN = CLANN.drop(['RXDDRUG','RXDDRGID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6327, 164)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLANN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the missing value\n",
    "CLANN = CLANN.dropna(axis=0, thresh=11, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6327, 164)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLANN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't to Don't know\n",
    "CLANN= CLANN.replace(999999,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't to Don't know\n",
    "CLANN= CLANN.replace(999,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refused to Don't know\n",
    "CLANN= CLANN.replace(777,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't know to No\n",
    "CLANN= CLANN.replace(9,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borderline to yes\n",
    "CLANN= CLANN.replace(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the missing value\n",
    "CLANN = CLANN.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6327, 164)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLANN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locking the data set and selecting the X(Independent) and Y (Dependent) Variable \n",
    "X= CLANN.iloc[:,1:164]\n",
    "y= CLANN.loc[:,['DIQ010']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the feature in standard form.\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "#Normalizing the dataset\n",
    "#from sklearn import preprocessing\n",
    "#X = preprocessing.normalize(X)\n",
    "#y = preprocessing.normalize(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4428, 163),)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1899, 163)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.71656382  0.          2.42854858 ...  0.38587744 -1.11696111\n",
      "   0.48925777]\n",
      " [-1.7162246   0.         -1.49223674 ...  0.38587744 -1.11696111\n",
      "   0.48925777]\n",
      " [-1.71588539  0.          0.58386772 ...  0.38587744 -1.11696111\n",
      "   0.48925777]\n",
      " ...\n",
      " [ 1.72440145  0.          0.7683358  ... -2.59149641 -1.11696111\n",
      "   0.48925777]\n",
      " [ 1.72474066  0.          0.19145379 ...  0.38587744  0.89528631\n",
      "   0.48925777]\n",
      " [ 1.7257583   0.          0.62746927 ...  0.38587744 -1.11696111\n",
      "   0.48925777]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True  True False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False  True  True  True\n",
      " False False False False False False False False False  True False  True\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False  True False False  True\n",
      "  True False False False False False False False False False False False\n",
      " False False False  True  True False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False]\n",
      "[ 34 142   1   1   1 141  20  63  30 100 135 109 136 131  57  45 115  23\n",
      "  79  39  50   2 114   1 138 120 143 132  85  74 126  19 130  92  91   1\n",
      "  72  60  40 118  69  43  48 101 140 129  64 139 116 133  89 123  52 127\n",
      "  47  94 125 113  71 112 128  24  62  84   1 137 144 105  13   1   1   1\n",
      "  75  33  73  22  95   7  26  41  46   1  87   1  70  58   1 102  59 119\n",
      "  32   3  21  37 106  44  15  11  97  83 134 122  14  54  99  55  36  35\n",
      "  86   1 111  38  67  28 103 108   1  98 107   1   1  81  68  51 110  29\n",
      "  77  49  82  27  53  76  90 124 117   1   1 104   9  61   1  25 121  42\n",
      "  66  56  12  80   5   4   8  65  96  88  78  31  10  16   6  18  17   1\n",
      "  93]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=22, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Logistic Regression trainning data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "regressor = LogisticRegression()\n",
    "rfe = RFE(regressor, 20)\n",
    "rfe = rfe.fit(X,y)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(rfe,y,test_size=0.30,random_state=0)\n",
    "#rfe = RFE(regressor,20 )\n",
    "#rfe = rfe.fit(X, Y )\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "regressor = LogisticRegression(random_state = 22)\n",
    "regressor.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=20, step=1, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# Need to select only the true variables\n",
    "print(rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Training data set accuracy\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Test Accuracy score:' , accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Yes       1.00      1.00      1.00       163\n",
      "         No       1.00      1.00      1.00      1736\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Yes', 'No']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  K-Nearest Neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the KNN model classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Model\n",
    "knn = knn.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8566858605246321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy score:' , accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Yes       0.34      0.05      0.08       215\n",
      "         No       0.87      0.99      0.92      1348\n",
      "\n",
      "avg / total       0.79      0.86      0.81      1563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Yes', 'No']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the SVM model classifier\n",
    "from sklearn.svm import SVC\n",
    "Model_svc = SVC(gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Model\n",
    "Model_svc.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "y_pred = Model_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8605246321177223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy score:' , accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Yes       0.33      0.01      0.03       215\n",
      "         No       0.86      1.00      0.92      1348\n",
      "\n",
      "avg / total       0.79      0.86      0.80      1563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Yes', 'No']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifcation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprting the Model and instantiating it into clf i.e. short name for classification\n",
    "from sklearn import tree\n",
    "clf_DT = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_DT = clf_DT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7523992322456814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy score:' , accuracy_score(y_test,y_pred))\n",
    "#print(\"Test set score: %f\" % clf.score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Yes       0.18      0.22      0.20       215\n",
      "         No       0.87      0.84      0.85      1348\n",
      "\n",
      "avg / total       0.78      0.75      0.76      1563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Yes', 'No']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X = (X_train)\n",
    "y = (y_train)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "     hidden_layer_sizes=(5,2),random_state=1)\n",
    "\n",
    "clf.fit(X, y.values.ravel())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., ..., 2., 2., 2.])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Training set score: %f\" % clf.score(X_train, y_train))\n",
    "#print(\"Test set score: %f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Yes       0.18      0.22      0.20       215\n",
      "         No       0.87      0.84      0.85      1348\n",
      "\n",
      "avg / total       0.78      0.75      0.76      1563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Yes', 'No']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8545634502483818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Average Ensemble for Classification for CLANN\n",
    "\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "X = X_train\n",
    "Y = y_train.values.ravel()\n",
    "seed = 22\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8624326310632042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Average Ensemble for Classification for CLANN\n",
    "\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = X_test\n",
    "Y = y_test\n",
    "seed = 22\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Yes       0.33      0.01      0.03       215\n",
      "         No       0.86      1.00      0.92      1348\n",
      "\n",
      "avg / total       0.79      0.86      0.80      1563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Yes', 'No']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
